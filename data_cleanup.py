"""
é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ¤œå‡ºãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ã„æ–¹:
  python check_duplicates.py              # é‡è¤‡ã‚’æ¤œå‡ºï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
  python check_duplicates.py --cleanup    # é‡è¤‡ã‚’æ¤œå‡ºã—ã¦è‡ªå‹•å‰Šé™¤
  python check_duplicates.py --export     # CSVå‡ºåŠ›
"""

import sys
import os
from collections import defaultdict
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from uguu.dynamo import DynamoDB


def find_duplicates(db):
    """é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ¤œå‡º"""
    print("[INFO] é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã®æ¤œç´¢é–‹å§‹...")
    print("=" * 80)
    
    # å…¨ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
    response = db.part_history.scan()
    all_records = response.get('Items', [])
    
    while 'LastEvaluatedKey' in response:
        response = db.part_history.scan(
            ExclusiveStartKey=response['LastEvaluatedKey']
        )
        all_records.extend(response.get('Items', []))
    
    print(f"[INFO] ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(all_records)}ä»¶")
    
    # â†“â†“â†“ ã“ã“ã‚’ä¿®æ­£ â†“â†“â†“
    # user_id + date ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆNoneã‚’é™¤å¤–ï¼‰
    grouped = defaultdict(list)
    invalid_records = []
    
    for record in all_records:
        user_id = record.get('user_id')
        date = record.get('date')
        
        # user_id ã¾ãŸã¯ date ãŒ None ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if not user_id or not date:
            invalid_records.append(record)
            continue
        
        key = (user_id, date)
        grouped[key].append(record)
    
    # ä¸æ­£ãªãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å ±å‘Š
    if invalid_records:
        print(f"\n[è­¦å‘Š] user_id ã¾ãŸã¯ date ãŒæ¬ è½ã—ã¦ã„ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰: {len(invalid_records)}ä»¶")
        for i, record in enumerate(invalid_records[:5], 1):  # æœ€åˆã®5ä»¶ã ã‘è¡¨ç¤º
            print(f"  {i}. user_id={record.get('user_id')}, date={record.get('date')}, joined_at={record.get('joined_at')}")
        if len(invalid_records) > 5:
            print(f"  ... ä»– {len(invalid_records) - 5}ä»¶")
        print()
    # â†‘â†‘â†‘ ã“ã“ã¾ã§ä¿®æ­£ â†‘â†‘â†‘
    
    # é‡è¤‡ã‚’æ¤œå‡º
    duplicates = []
    total_extra_records = 0
    
    for (user_id, date), records in sorted(grouped.items()):
        if len(records) > 1:
            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ¸ˆã¿ã‚’é™¤å¤–ã—ãŸæœ‰åŠ¹ãªãƒ¬ã‚³ãƒ¼ãƒ‰æ•°
            active_records = [r for r in records if r.get('status') != 'cancelled']
            cancelled_records = [r for r in records if r.get('status') == 'cancelled']
            
            if len(active_records) > 1:
                # æœ‰åŠ¹ãªãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯é‡è¤‡
                duplicates.append({
                    'user_id': user_id,
                    'date': date,
                    'total_count': len(records),
                    'active_count': len(active_records),
                    'cancelled_count': len(cancelled_records),
                    'active_records': active_records,
                    'cancelled_records': cancelled_records,
                    'severity': 'high'
                })
                total_extra_records += len(active_records) - 1
            elif len(cancelled_records) > 1:
                # ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ¸ˆã¿ãŒè¤‡æ•°ã‚ã‚‹å ´åˆ
                duplicates.append({
                    'user_id': user_id,
                    'date': date,
                    'total_count': len(records),
                    'active_count': len(active_records),
                    'cancelled_count': len(cancelled_records),
                    'active_records': active_records,
                    'cancelled_records': cancelled_records,
                    'severity': 'low'
                })
                total_extra_records += len(cancelled_records) - 1
    
    # çµæœè¡¨ç¤º
    print(f"\n{'='*80}")
    print(f"é‡è¤‡æ¤œå‡ºçµæœ")
    print(f"{'='*80}")
    print(f"é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—æ•°: {len(duplicates)}ä»¶")
    print(f"ä½™åˆ†ãªãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_extra_records}ä»¶")
    print(f"{'='*80}\n")
    
    if duplicates:
        print("ã€é‡è¤‡ã®è©³ç´°ã€‘\n")
        
        # é‡å¤§åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        duplicates.sort(key=lambda x: (x['severity'] == 'low', x['date']), reverse=True)
        
        for i, dup in enumerate(duplicates, 1):
            severity_label = "ğŸ”´ é‡å¤§" if dup['severity'] == 'high' else "ğŸŸ¡ è»½å¾®"
            print(f"{i}. {severity_label}")
            print(f"   User ID: {dup['user_id']}")
            print(f"   Date: {dup['date']}")
            print(f"   ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {dup['total_count']}ä»¶")
            print(f"   â”œâ”€ æœ‰åŠ¹: {dup['active_count']}ä»¶")
            print(f"   â””â”€ ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ¸ˆã¿: {dup['cancelled_count']}ä»¶")
            
            # æœ‰åŠ¹ãªãƒ¬ã‚³ãƒ¼ãƒ‰
            if dup['active_records']:
                print(f"   æœ‰åŠ¹ãªãƒ¬ã‚³ãƒ¼ãƒ‰:")
                for j, record in enumerate(dup['active_records'], 1):
                    joined_at = record.get('joined_at', 'N/A')
                    print(f"     [{j}] {joined_at}")
            
            # ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ¸ˆã¿ãƒ¬ã‚³ãƒ¼ãƒ‰
            if dup['cancelled_records']:
                print(f"   ã‚­ãƒ£ãƒ³ã‚»ãƒ«æ¸ˆã¿ãƒ¬ã‚³ãƒ¼ãƒ‰:")
                for j, record in enumerate(dup['cancelled_records'], 1):
                    joined_at = record.get('joined_at', 'N/A')
                    print(f"     [{j}] {joined_at}")
            
            print()
    else:
        print("é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    return duplicates, total_extra_records


def cleanup_duplicates(db, duplicates, batch_size=50):
    """
    é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å®‰å…¨ã«å‰Šé™¤ï¼ˆæ­£ã—ã„ã‚­ãƒ¼æ§‹é€ ã‚’ä½¿ç”¨ï¼‰
    """
    import time
    
    print("\n" + "=" * 80)
    print(f"é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹ï¼ˆ{batch_size}ä»¶ãšã¤å‡¦ç†ï¼‰")
    print("=" * 80)
    
    deleted_count = 0
    error_count = 0
    error_details = []
    
    total_groups = len(duplicates)
    
    for i, dup in enumerate(duplicates, 1):
        user_id = dup['user_id']
        date = dup['date']
        
        if i % 10 == 0 or i == 1:
            print(f"[{i}/{total_groups}] å‡¦ç†ä¸­...", end='\r')
        
        try:
            if dup['active_count'] > 1:
                # joined_at ã§æœ€æ–°ã®ã‚‚ã®ã‚’é¸æŠ
                active_records = sorted(
                    dup['active_records'], 
                    key=lambda x: x.get('joined_at', ''), 
                    reverse=True
                )
                keep_record = active_records[0]
                delete_records = active_records[1:]
                
                # å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ï¼ˆæ­£ã—ã„ã‚­ãƒ¼ã‚’ä½¿ç”¨ï¼‰
                for record in delete_records:
                    try:
                        # user_id + joined_at ã§å‰Šé™¤
                        db.part_history.delete_item(
                            Key={
                                'user_id': user_id,
                                'joined_at': record.get('joined_at')
                            }
                        )
                        deleted_count += 1
                    except Exception as e:
                        error_msg = f"User: {user_id[:8]}..., Date: {date}, JoinedAt: {record.get('joined_at')} - {str(e)[:80]}"
                        error_details.append(error_msg)
                        error_count += 1
                        if error_count <= 5:
                            print(f"\nâœ— ã‚¨ãƒ©ãƒ¼ [{error_count}]: {error_msg}")
                
        except Exception as e:
            error_count += 1
            error_msg = f"User: {user_id[:8]}..., Date: {date} - {str(e)[:80]}"
            error_details.append(error_msg)
            print(f"\nâœ— ã‚¨ãƒ©ãƒ¼ [{error_count}]: {error_msg}")
        
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã”ã¨ã«ç¢ºèª
        if i % batch_size == 0 and i < total_groups:
            print(f"\n\n{'='*80}")
            print(f"ğŸ“Š é€²æ—ãƒ¬ãƒãƒ¼ãƒˆ ({i}/{total_groups}ä»¶å‡¦ç†å®Œäº†)")
            print(f"{'='*80}")
            print(f"å‰Šé™¤å®Œäº†: {deleted_count}ãƒ¬ã‚³ãƒ¼ãƒ‰")
            print(f"ã‚¨ãƒ©ãƒ¼: {error_count}ä»¶")
            
            if error_count > 0:
                print(f"\nç›´è¿‘ã®ã‚¨ãƒ©ãƒ¼:")
                for err in error_details[-5:]:
                    print(f"  â€¢ {err}")
            
            print(f"\næ¬¡ã®{min(batch_size, total_groups - i)}ä»¶ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
            response = input("ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no/skip): ")
            
            if response.lower() == 'no':
                print("\nä¸­æ–­ã—ã¾ã—ãŸ")
                break
            elif response.lower() == 'skip':
                print(f"\næ®‹ã‚Š{total_groups - i}ä»¶ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                break
            
            print(f"\nå‡¦ç†ã‚’å†é–‹ã—ã¾ã™...\n")
            time.sleep(0.5)
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\n\n{'='*80}")
    print(f"ğŸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
    print(f"{'='*80}")
    print(f"å‡¦ç†ã‚°ãƒ«ãƒ¼ãƒ—æ•°: {i}ä»¶")
    print(f"å‰Šé™¤ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {deleted_count}ä»¶")
    print(f"ã‚¨ãƒ©ãƒ¼ä»¶æ•°: {error_count}ä»¶")
    print("=" * 80)
    
    if error_count > 0:
        print(f"\nâš ï¸  ã‚¨ãƒ©ãƒ¼è©³ç´°:")
        for err in error_details[:10]:  # æœ€åˆã®10ä»¶
            print(f"  â€¢ {err}")
        if len(error_details) > 10:
            print(f"  ... ä»– {len(error_details) - 10}ä»¶")


def export_to_csv(duplicates, filename='duplicates_report.csv'):
    """é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’CSVã«å‡ºåŠ›"""
    import csv
    
    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow([
            'User ID', 'Date', 'Total Count', 'Active Count', 
            'Cancelled Count', 'Severity', 'Active Records', 'Cancelled Records'
        ])
        
        for dup in duplicates:
            active_times = ', '.join([r.get('joined_at', 'N/A') for r in dup['active_records']])
            cancelled_times = ', '.join([r.get('joined_at', 'N/A') for r in dup['cancelled_records']])
            
            writer.writerow([
                dup['user_id'],
                dup['date'],
                dup['total_count'],
                dup['active_count'],
                dup['cancelled_count'],
                dup['severity'],
                active_times,
                cancelled_times
            ])
    
    print(f"\nãƒ¬ãƒãƒ¼ãƒˆã‚’ {filename} ã«å‡ºåŠ›ã—ã¾ã—ãŸ")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "=" * 80)
    print("é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("=" * 80 + "\n")
    
    # å¼•æ•°ãƒã‚§ãƒƒã‚¯
    do_cleanup = '--cleanup' in sys.argv
    do_export = '--export' in sys.argv
    
    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã®æŒ‡å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰
    batch_size = 50
    if '--batch' in sys.argv:
        try:
            batch_idx = sys.argv.index('--batch')
            batch_size = int(sys.argv[batch_idx + 1])
            print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}ä»¶\n")
        except:
            print("âš  --batch ã®å€¤ãŒä¸æ­£ã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼ˆ50ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™\n")
    
    if do_cleanup:
        print(f"âš ï¸  ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¢ãƒ¼ãƒ‰")
        print(f"â€¢ {batch_size}ä»¶ã”ã¨ã«ç¢ºèª")
        print(f"â€¢ é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’è‡ªå‹•å‰Šé™¤")
        print(f"â€¢ ã‚¨ãƒ©ãƒ¼ã¯å³åº§ã«è¡¨ç¤º")
        confirm = input("\nç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (yes/no): ")
        if confirm.lower() != 'yes':
            print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
    
    # DynamoDBæ¥ç¶š
    try:
        db = DynamoDB()
        print("\nDynamoDBã«æ¥ç¶šã—ã¾ã—ãŸ\n")
    except Exception as e:
        print(f"DynamoDBæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # é‡è¤‡æ¤œå‡º
    duplicates, total_extra = find_duplicates(db)
    
    # CSVå‡ºåŠ›
    if do_export and duplicates:
        export_to_csv(duplicates)
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    if do_cleanup and duplicates:
        cleanup_duplicates(db, duplicates, batch_size=batch_size)
        
        print("\n\nå†åº¦é‡è¤‡ã‚’ç¢ºèªã—ã¾ã™ã‹ï¼Ÿ (yes/no): ", end='')
        if input().lower() == 'yes':
            print("\nå†æ¤œç´¢ä¸­...")
            find_duplicates(db)
    
    print("\n" + "=" * 80)
    print("å‡¦ç†å®Œäº†")
    print("=" * 80)


if __name__ == '__main__':
    main()